{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: Statistical Experiments and Significance Testing\n",
    "\n",
    "\n",
    "The goal of a statistical experiment is to answer to hypothesis by gathering data and apply statistical tools to draw inferences. Here are the different concepts and tools for designing experiments, analyzing data, and drawing conclusions:\n",
    "* A/B testing\n",
    "* Hypothesis Test\n",
    "* Resampling\n",
    "* Statistical significance and p-Values\n",
    "* t-Tests\n",
    "* Multiple testing\n",
    "* Degrees of freedom\n",
    "* ANOVA \n",
    "* Chi-square test\n",
    "* Multi-arm bandit algorithm\n",
    "* Power and sample size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A/B testing\n",
    "\n",
    "A/B testing is a method for comparing two versions of a variable to determine which one performs better according to a certain metric. For example, testing if jacket red performes better that jacket blue in terms of the number of jackets bought. Here the key elements of an A/B testing:\n",
    "\n",
    "* Variable \n",
    "    * The treatment under study: color of the jacket, drugs, web headlines, the color of a layout.\n",
    "* Control Group and treatment Group \n",
    "    * The subjects (buyer, patient etc) are randomly divided into two groups: the control group (A) receives the original version, while the treatment group (B) receives the variant.\n",
    "* Test statistic (or metric)\n",
    "    * The metric or set of metrics used to evaluate the performance of each version. It can be binary variable such as click-through rates or conversion rates and or continuous variable (profit, pages visited).\n",
    "* Statistical Analysis\n",
    "    * After the test is conducted, statistical methods are used to analyze the results and determine whether the differences in outcomes between the two versions are statistically significant.\n",
    "\n",
    "\n",
    "#### Applications\n",
    "A/B testing is mainly applied in a web context:\n",
    "\n",
    "* Marketing\n",
    "    * Optimizing campaign strategies: email content, and sending times.\n",
    "* Website Optimization\n",
    "    * Improving user experience.\n",
    "* Pricing Strategies\n",
    "    * Evaluating customer response to different pricing models.\n",
    "\n",
    "#### Limitations\n",
    "\n",
    "* Sample Size\n",
    "    * A/B tests require sufficiently large sample sizes to make any differences between the two groups statistically significant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis tests (significance tests)\n",
    "\n",
    "Hypothesis tests are statistical method to determine whether a result is due to random chance. In other words, the primary role of significance tests, is to prevent us from being fooled by random variations. The process involves comparing two hypotheses, the null hypothesis and the alternative hypothesis:\n",
    "\n",
    "* Null Hypothesis (H0)\n",
    "    * It posits that there is no difference, and any difference is solely due to chance. Based on sample evidence, the test aims to either reject the null hypothesis - the difference is to extreme for only being to chance - or failed to reject - the difference is could likeky originate from random chance.\n",
    "    \n",
    "*   Alternative Hypothesis (H1)\n",
    "    * It is the hypothesis in case of rejection of the null hypothesis. The null and alternative hypotheses must account for all possibilities.\n",
    "\n",
    "*   One-way Test\n",
    "    * The test looks only for a difference in one direction. Is A greater than B? If the null hypothesis is rejected: it is unlikly that chance produces a result where A is as greater to B that the one observed. Therefore, A seems better than BL It is useful for drug testing, where only a better result matters. \n",
    "\n",
    "*   Two-way Test \n",
    "    * This test looks for any significant difference, regardless of direction. Is A greater or lower than B? If the null hypothesis is rejected: it is unlikly that chance produce a result where A is as superieur or as inferior to B than the one observed.\n",
    "\n",
    "#### Applications\n",
    "Hypothesis testing finds applications in numerous fields  such as:\n",
    "\n",
    "* A/B test\n",
    "    * An hypothesis test serves as a next step in analyzing the results of an A/B test, or any randomized experiment, to rigorously evaluate the observed differences between groups A and B.\n",
    "* Medical research \n",
    "    * Testing whether a new drug is more effective than existing treatments. On-way test where the null hypothesis states that there is no difference between the two drugs, while the alternative hypothesis states the new does better.\n",
    "* Sales optimization\n",
    "    * Determining if a change in packaging leads to improved sales. \n",
    "\n",
    "\n",
    "#### Limitations\n",
    "Despite its broad utility, hypothesis testing comes with certain limitations:\n",
    "\n",
    "* Risk of errors\n",
    "    * There is a risk of making Type I errors (falsely rejecting the null hypothesis) or Type II errors (failing to reject a false null hypothesis).\n",
    "\n",
    "* Directional bias in one-way tests\n",
    "    * While one-way tests can be powerful for testing specific hypotheses, they may overlook significant effects in the opposite direction.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling\n",
    "\n",
    "Resampling involves drawing repeated samples from observed data, mainly through:\n",
    "\n",
    "* Bootstrap: Estimating the reliability of statistics by sampling with replacement (see chapter 2).\n",
    "* Permutation Tests: Testing hypotheses by shuffling data labels to simulate the null hypothesis\n",
    "\n",
    "#### Permutation Test\n",
    "\n",
    "Permutation test is a non-parametric statistical method used for hypothesis testing. Indeed, this test asses the significance of a difference between groups without assuming a specific underlying data distribution. Here the main steps:\n",
    "\n",
    "1. Gather the values from the different groups (e.g. A and B) in one dataset\n",
    "2. Draw randomly the values without replacements to form new groups (A',B') of the original size (A,B). \n",
    "3. Measure the test statistic understudy (e.g. the mean difference: mean(A')-mean(B')) and record it.\n",
    "4. Repeat R times the steps 2 and 3 to obtain a permutation distribution of the test statistic \n",
    "5. Compared the original metric mean(A)-mean(B) to the permutation distribution\n",
    "\n",
    "It the original metric lies within the permutation distribution, the difference mean(A)-mean(B) could be obtained by random process. Otherwise, the difference is too extreme to be generated randomly. Thus the difference is statistically significant.\n",
    "\n",
    "\n",
    "#### Applications\n",
    "Permutation tests can be applied to various types of data — whether numeric or binary — and are not constrained by equal sample sizes or the assumption of normal distribution in data. This flexibility positions resampling as a more universally strategy for hypothesis testing.\n",
    "\n",
    "\n",
    "#### Limitations\n",
    "\n",
    "Permutation tests are insightful but come with limitations compared to conventional statistical tests:\n",
    "\n",
    "* Computational demands\n",
    "    * They can be computationally intensive, especially with large datasets.\n",
    "* Theoretical Insights\n",
    "    * Lacks insights into the theoretical distribution of data, limiting broader inferences beyond the observed dataset.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Statistical Significance and P-Values\n",
    "Statistical significance is a measure that tells us how likely it is that an effect observed in a dataset occurs due to chance. Thus, it helps to decide if the results are unusual enough to reject the null hypothesis. For that, we often use the p-value, which quantifies the probability of obtaining results at least as extreme as the ones observed, assuming that the null hypothesis is true. There are different tools to obtain it:\n",
    "\n",
    "* Permutation Test\n",
    "    * From the null hypothesis, it generates the metric of interest by random chance. Then, we calculate the proportion of times that the permutation test produces a metric equal to or greater than the observed one.\n",
    "* Chance Model\n",
    "    * A chance model, such as a binomial or chi-square distribution, can simulate the distribution of the data in case they were purely due to chance. Then, we calculate the proportion of times that the chance produces data equal to or greater than the observed one.\n",
    "\n",
    "To accept or reject the null hypothesis based on the p-value, we often use a threshold named the significance level, denoted as alpha (α). The threshold is commonly set at 5% or 1%, which is arbitrary. If the p-value is above the predefined threshold, we conclude that the observed values are likely to be produced by chance and the effect is not statistically significant.\n",
    "\n",
    "#### Applications\n",
    "Significance testing and p-values are mainly used to prevent researchers and data scientists from being misled by random chance. It is a metric among others that can help in the decision process, but it should not be the sole factor relied upon.\n",
    "\n",
    "#### Limitations\n",
    "* Practical Significance\n",
    "    * P-values do not provide any information about the importance of the effect under study.\n",
    "\n",
    "* Misinterpretation\n",
    "    * There's a common misconception that a p-value tells you the probability that the null hypothesis is true or false. However, it merely indicates the probability of observing the data if the null hypothesis were true.\n",
    "\n",
    "* Arbitrary Thresholds\n",
    "    * The common threshold of 5% for declaring statistical significance is arbitrary and can lead to the neglect of potentially important findings that don't meet this cutoff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-tests\n",
    "\n",
    "The t-tests are  used to determine if there is a significant difference between the means of two groups. It has been shown to be a good approximation of the permutation tests for calculating the p-value for an A/B test.\n",
    "\n",
    "The t-test relies on the t-statistic, which is calculated from sample data as:\n",
    "t-statistic =[mean(A)-mean(B)]/[s/n**0.5]\n",
    "with s the pooled standard deviation of the two samples, and n is the sample size (assuming equal sizes for simplicity). This statistic follows a t-distribution. Thus, the p-value corresponds to the probability that the t-distribution produces a value greater than the absolute value of the calculated t-statistic (for a one-tailed test).\n",
    "\n",
    "\n",
    "#### Applications\n",
    "* Academic Research\n",
    "    * Understanding how far a sample mean deviates from a hypothesized population mean can help researchers in fields from psychology to economics validate theories and models.\n",
    "\n",
    "* Product Testing \n",
    "    * Compare the effectiveness or quality of different product versions/\n",
    "\n",
    "\n",
    "\n",
    "#### Limitations with a Focus on the T-Statistic\n",
    "* Distribution assumptions\n",
    "    * The accuracy of the t-statistic depends on the assumption that the data follows a normal distribution. Deviations from normality can lead to incorrect t-statistic calculations and conclusions.\n",
    "\n",
    "* Sensitivity to sample size\n",
    "    * The t-statistic's reliability increases with sample size. With very small samples, the t-statistic might not accurately reflect the population parameters, leading to Type I or Type II errors.\n",
    "\n",
    "* Dependency on Variance Homogeneity\n",
    "    * When comparing two groups, the calculation of the t-statistic assumes homogeneity of variances. If this assumption is violated, the resulting t-statistic might not accurately reflect the true difference between groups, although adjustments like Welch's correction exist to mitigate this issue.\n",
    "\n",
    "* Multiple testing\n",
    "    * In research studies or data mining projects where there is a high degree of multiplicity, such as multiple comparisons, analysis of numerous variables, or the use of various models, there is an increase risk of mistakenly identifying findings as statistically significant merely due to random chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA\n",
    "\n",
    "It is a statistical method used to compare the means of two or more samples to understand if at least one of the sample means significantly differs from the others. ANOVA operates under the null hypothesis that all group means are equal, and any observed differences are due to chance. The method extends the t-test, which is limited to comparing two groups. Here the main methods:\n",
    "\n",
    "* F-tests\n",
    "    * It calculates an F-statistic based on the ratio of variance between the groups to the variance within the groups. A significant F-statistic suggests that at least one group mean significantly differs from the others. The F-test is advantageous because it can handle multiple groups simultaneously, reducing the risk of Type I errors by multiple testing.\n",
    "\n",
    "* Two-Way ANOVA\n",
    "    * While a basic (one-way) ANOVA compares means across a single factor, Two-Way ANOVA allows for the examination of two independent factors simultaneously. \n",
    "\n",
    "\n",
    "### Applications\n",
    "\n",
    "* Feature Selection\n",
    "    * It can help in identifying which variables significantly impact a target variable, allowing for the reduction of model complexit.\n",
    "\n",
    "* Quality Control\n",
    "    * ANOVA can compare the effects of different process parameters or strategies on product quality or operational efficiency.\n",
    "\n",
    "### Limitations\n",
    "* Assumption of Normality\n",
    "    * It assumes that the data for each group are drawn from a normal distribution. \n",
    "\n",
    "* Homogeneity of Variances\n",
    "    * ANOVA requires that the variances within each of the groups being compared are approximately equal. \n",
    "\n",
    "* Independence of Observations\n",
    "    * The method assumes that the observations within each group are independent of each other. In some study designs, such as repeated measures or clustered samples, this assumption may not be met.\n",
    "\n",
    "* Limited to Mean Comparisons\n",
    "    * ANOVA focuses on differences in means among groups. It does not provide information on median differences or other aspects of distribution shapes, which might be of interest in some analyses.\n",
    "\n",
    "* Multiple Comparisons Issue\n",
    "    * While ANOVA can indicate that there is a significant difference among group means, it does not specify where these differences lie. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Square test\n",
    "\n",
    "The Chi-Square test is used to evaluate whether the observed frequencies of a categorical variable deviates significantly from the expected frequencies. The test calculates a Chi-Square statistic, which measures the discrepancy between observed and expected frequencies. From it, the p-Value can be computed in two different ways:\n",
    "* Using  Chi-Square distribution\n",
    "    * The p-Value corresponds to the probability that the chi-square distribution produces a value greater than the absolute value of the calculated t-statistic\n",
    "* Using a permutation test\n",
    "    * The p-value corresponds to the frequency that the resampled sum of squared deviations exceed the observed.\n",
    "\n",
    "The chi-square statistic is mainly used for two tests:\n",
    "* Goodness-of-fit test\n",
    "    * It determines if a sample data matches a population with a specific distribution. For instance, it can test if the number of individuals with certain characteristics in a sample is consistent with the expected distribution of those characteristics in the general population.\n",
    "* Test of Independence\n",
    "    * It assesses whether there is a significant association between two categorical variables. For example, it can be used to determine if there is a relationship between gender (male/female) and preference for a particular type of product (Product A/Product B). Mainly use with contingency table.\n",
    "\n",
    "\n",
    "#### Application\n",
    "\n",
    "* Experimental Research\n",
    "    * It is used for establishing statistical significance between categorical variables in experimental research.\n",
    "* Data Science\n",
    "    * It can be used for determining appropriate sample sizes for web experiments, such as A/B testing. By analyzing pilot studies using the Chi-Square test, we can estimate the minimum number of participants needed to achieve statistically significant results.\n",
    "\n",
    "\n",
    "### Limitations\n",
    "* Requirement for categorical data\n",
    "    * It cannot be applied to continuous data.\n",
    "\n",
    "* Sample size restrictions\n",
    "    * The test requires a sufficient sample size to ensure reliable results.\n",
    "    \n",
    "* Assumption of independence\n",
    "    * The observations need to be independent of each other. \n",
    "\n",
    "* No information on direction\n",
    "    * While the Chi-Square test can indicate whether variables are related, it does not provide information on the direction or strength of the relationship. \n",
    "\n",
    "* Sensitivity to sample size\n",
    "    * Extremely large sample sizes may lead to significant Chi-Square values for trivial differences, while small sample sizes may lack the power to detect meaningful associations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Arm Bandit Algorithm\n",
    "\n",
    "Multi-Arm Bandit Algorithm (MABA) is a procedure that optimize the testing of new possibilities. MABA uses the information during the experiment to oriente the distribution process limiting the waste (time and material). For example, in the context of a medical experiment aiming to test the efficiency of four different drugs across 100 subjects, a traditional approach might divide the subjects equally among the drugs, with each drug being administered to 25 subjects. In contrast, the MABA starts by distributing the drugs among subjects but then continuously re-adjusts the allocation based on the observed outcomes, often named the rate reward (e.g., improvement in health indicators, side effects), from the initial distributions.\n",
    "\n",
    "#### Applications\n",
    "\n",
    "* Clinical Trials\n",
    "    * Dynamically allocating patients to different treatment to find the most effective treatment and treat patients effectively during the trial.\n",
    "* Website Optimization\n",
    "    * Continuously testing different versions of web page elements such as headlines or layouts.\n",
    "\n",
    "\n",
    "#### Limitations\n",
    "\n",
    "* Stationnary Assumptions\n",
    "    * MABA assumes stationary rate reward distributions, which may not hold in dynamic environments where the probabilities of rewards change over time.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power and sample size\n",
    "\n",
    "The power is the probability of correctly rejecting the null hypothesis or in other words, the probability to detect an effect when there is one. This probability depends on :\n",
    "\n",
    "* Size effect  \n",
    "    * It is the magnitude of the effect (or difference). Stronger is the importance of the effect, easier is its detection, thus higher is the probability of correctly detect it. In contrast, the statistical significance tells us that there is a difference but gives no information about the importance of the effect.\n",
    "* Sample size\n",
    "    * The larger the sample size, the easier it is to observe smaller differences. For instance, a 10% difference observed in a sample size of 200 yields a numerical difference of 20 (10% of 200), whereas the same percentage difference in a sample size of 20,000 yields a numerical difference of 2,000 (10% of 20,000). T\n",
    "* Significance level (α)\n",
    "    * The threshold for rejecting the null hypothesis. A higher α increases the risk of Type I error (rejecting the null hypothesis when it is true) but also increases power. The most common α level is 0.05.\n",
    "\n",
    "#### Applications\n",
    "\n",
    "* Designing Studies\n",
    "    * Before conducting a study, power analysis allows to determine the necessary sample size to detect an effect of interest with a desired power, typically 0.80 or 80%. This ensures that the study is neither overpowered (wasting resources) nor underpowered (risking missing a true effect).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
